# ETL Pipeline для расчёта отчётности

Этот репозиторий содержит реализацию полноценного ETL-пайплайна с оркестрацией на Apache Airflow и обработкой данных через Apache Spark и PostgreSQL. Пайплайн охватывает задачи загрузки данных, расчёта витрин, формирования регламентированного отчёта и экспорта данных в CSV.

---

## Задачи проекта

### Задача 1.1: Загрузка CSV-данных в слой DS

**Контекст:**
В результате сбоя при миграции банковской frontend-системы часть операций за конец 2017 – начало 2018 осталась в виде CSV-файлов. Данные нужно загрузить в PostgreSQL в схему `DS`, соблюдая актуальность записей и обработку разных форматов дат.

**Требования:**

* Загрузка данных из CSV-файлов в таблицы:

  * `DS.MD_ACCOUNT_D`, `DS.MD_CURRENCY_D`, `DS.MD_EXCHANGE_RATE_D`
  * `DS.MD_LEDGER_ACCOUNT_S`
  * `DS.FT_POSTING_F`, `DS.FT_BALANCE_F`
* Учет актуальности данных через поля `data_actual_date` и `data_actual_end_date`
* Логирование в схеме `LOGS` (с указанием времени начала/конца загрузки и дополнительной информации)
* Поддержка "insert-or-update" стратегии
* Обработка различных форматов даты

---

### Задача 1.2: Расчёт витрин `TURNOVER` и `BALANCE`

**Цель:**
Создание и наполнение аналитических витрин в схеме `DM`:

* `DM.DM_ACCOUNT_TURNOVER_F` – витрина оборотов
* `DM.DM_ACCOUNT_BALANCE_F` – витрина остатков

**Реализовано:**

* Хранимая процедура `ds.fill_account_turnover_f(i_OnDate DATE)`

  * Вычисление дневных оборотов по дебету и кредиту
  * Конвертация сумм в рубли
* Хранимая процедура `ds.fill_account_balance_f(i_OnDate DATE)`

  * Вычисление дневных остатков с учётом типа счёта (актив/пассив)
* Заполнение витрин за каждый день января 2018
* Логирование расчётов витрин

---

### Задача 1.3: Расчёт регламентированной отчётности (Форма 101)

**Цель:**
Формирование итогового отчёта `DM.DM_F101_ROUND_F` по агрегированным остаткам и оборотам на конец января 2018.

**Особенности:**

* Группировка по балансовым счетам второго порядка
* Учет рублевых и валютных остатков/оборотов
* Хранимая процедура `dm.fill_f101_round_f(i_OnDate DATE)`

  * Отчёт за месяц формируется при передаче даты начала следующего месяца (например, 01.02.2018)
* Логирование начала и окончания расчёта

---

### Задача 1.4: Экспорт и импорт итогового отчёта

**Цель:**
Экспорт отчётной формы 101 в CSV, а также реализация импорта обратно в БД (например, в `DM_F101_ROUND_F_V2`) с простым логированием.

**Реализовано:**

* Скрипт экспорта с заголовками колонок
* Скрипт импорта с поддержкой перезаписи
* Минимальное логирование в консоль и таблицу

---

## Инструкция по запуску

### 1. Загрузка Spark JAR-файлов

Перед началом работы выполните скрипт:

```bash
./download_spark_jars.sh
```

> Убедитесь, что скрипт исполняемый:
> `chmod +x download_spark_jars.sh`

---

### 2. Запуск инфраструктуры

Поднимите все компоненты через Docker Compose:

```bash
docker compose up
```

> Это создаст и запустит Airflow, PostgreSQL, Spark и необходимые зависимости.

---

### 3. Запуск DAG в Airflow

Перейдите в веб-интерфейс Airflow:

[http://localhost:8080](http://localhost:8080)

Там вы увидите DAG, реализующий ETL-пайплайн. Его можно запустить вручную и отслеживать выполнение задач.

---

## Используемые технологии

* **Apache Airflow** – оркестрация пайплайна
* **Apache Spark** – обработка и загрузка CSV
* **PostgreSQL** – хранилище данных
* **Docker / Docker Compose** – контейнеризация
* **Python** – вспомогательные скрипты, логика импорта/экспорта

