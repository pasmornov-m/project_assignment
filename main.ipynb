{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c00165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cc771d",
   "metadata": {},
   "source": [
    "Чтобы заработало локально, изменить в config.py: POSTGRES_HOST = \"db\" -> POSTGRES_HOST = \"localhost\"\n",
    "и путь до spark_jars в spark_client прописать локальный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0aa91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl.stages import sync_ds_tables\n",
    "from config import db_name, ds_schema_name, ds_sql_filename, raw_files_info, ds_tables_pkeys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c72a13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-30 19:43:21,032 [INFO] etl.stages: === Начало процесса синхронизации DS ===\n",
      "2025-06-30 19:43:21,062 [INFO] etl.stages: Начало: 2025-06-30 19:43:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-30 19:43:26,077 [INFO] db_utils.check_postges: Проверка/создание БД 'project', схемы 'ds', и таблиц из 'db_utils/ds_tables.sql'\n",
      "2025-06-30 19:43:26,089 [INFO] db_utils.check_postges: Проверка существования базы данных 'project'\n",
      "2025-06-30 19:43:26,097 [INFO] db_utils.check_postges: База данных 'project' уже существует.\n",
      "2025-06-30 19:43:26,132 [INFO] db_utils.check_postges: Создаю схему 'ds' в базе 'project' (если она отсутствует)\n",
      "2025-06-30 19:43:26,139 [INFO] db_utils.check_postges: Схема 'ds' готова.\n",
      "2025-06-30 19:43:26,180 [INFO] db_utils.check_postges: Читаю SQL из файла 'db_utils/ds_tables.sql'\n",
      "2025-06-30 19:43:26,188 [INFO] db_utils.check_postges: Выполняю SQL для создания таблиц\n",
      "2025-06-30 19:43:26,199 [INFO] db_utils.check_postges: Таблицы успешно созданы.\n",
      "2025-06-30 19:43:26,211 [INFO] etl.stages: Начало обновления таблиц в схеме 'ds' БД 'project'\n",
      "2025-06-30 19:43:29,085 [INFO] etl.stages: Данные из csv успешно загружены: ['ft_balance_f', 'ft_posting_f', 'md_account_d', 'md_currency_d', 'md_exchange_rate_d', 'md_ledger_account_s']\n",
      "2025-06-30 19:43:29,088 [INFO] etl.stages: Truncate таблицы ds.ft_posting_f перед полной загрузкой\n",
      "2025-06-30 19:43:29,140 [INFO] etl.stages: Таблица успешно очищена.\n",
      "2025-06-30 19:43:29,142 [INFO] etl.stages: Вставка данных в ft_posting_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 81:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-30 19:43:31,572 [INFO] etl.stages: Загрузка данных в ft_posting_f завершена.\n",
      "2025-06-30 19:43:31,576 [INFO] etl.stages: Обновление данных в ds.ft_balance_f с помощью upsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-30 19:43:32,834 [INFO] etl.stages: Данные успешно обновлены в ds.ft_balance_f\n",
      "2025-06-30 19:43:32,843 [INFO] etl.stages: Обновление данных в ds.md_account_d с помощью upsert\n",
      "2025-06-30 19:43:33,610 [INFO] etl.stages: Данные успешно обновлены в ds.md_account_d\n",
      "2025-06-30 19:43:33,614 [INFO] etl.stages: Обновление данных в ds.md_currency_d с помощью upsert\n",
      "2025-06-30 19:43:34,374 [INFO] etl.stages: Данные успешно обновлены в ds.md_currency_d\n",
      "2025-06-30 19:43:34,377 [INFO] etl.stages: Обновление данных в ds.md_exchange_rate_d с помощью upsert\n",
      "2025-06-30 19:43:35,063 [INFO] etl.stages: Данные успешно обновлены в ds.md_exchange_rate_d\n",
      "2025-06-30 19:43:35,069 [INFO] etl.stages: Обновление данных в ds.md_ledger_account_s с помощью upsert\n",
      "2025-06-30 19:43:35,787 [INFO] etl.stages: Данные успешно обновлены в ds.md_ledger_account_s\n",
      "2025-06-30 19:43:35,793 [INFO] etl.stages: Обновление всех таблиц завершено за 9.58 секунд.\n",
      "2025-06-30 19:43:35,797 [INFO] etl.stages: Окончание: 2025-06-30 19:43:35\n",
      "2025-06-30 19:43:35,799 [INFO] etl.stages: Длительность: 0:00:14.734871\n",
      "2025-06-30 19:43:35,902 [INFO] db_utils.check_postges: Проверка/создание БД 'project', схемы 'logs', и таблиц из 'db_utils/log_table.sql'\n",
      "2025-06-30 19:43:35,930 [INFO] db_utils.check_postges: Проверка существования базы данных 'project'\n",
      "2025-06-30 19:43:35,935 [INFO] db_utils.check_postges: База данных 'project' уже существует.\n",
      "2025-06-30 19:43:35,992 [INFO] db_utils.check_postges: Создаю схему 'logs' в базе 'project' (если она отсутствует)\n",
      "2025-06-30 19:43:36,002 [INFO] db_utils.check_postges: Схема 'logs' готова.\n",
      "2025-06-30 19:43:36,059 [INFO] db_utils.check_postges: Читаю SQL из файла 'db_utils/log_table.sql'\n",
      "2025-06-30 19:43:36,072 [INFO] db_utils.check_postges: Выполняю SQL для создания таблиц\n",
      "2025-06-30 19:43:36,080 [INFO] db_utils.check_postges: Таблицы успешно созданы.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 97:====================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-30 19:43:37,692 [INFO] etl.stages: === Конец процесса ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sync_ds_tables(db_name=db_name, \n",
    "               schema_name=ds_schema_name, \n",
    "               sql_filename=ds_sql_filename, \n",
    "               raw_files_info=raw_files_info, \n",
    "               tables_pkeys=ds_tables_pkeys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
